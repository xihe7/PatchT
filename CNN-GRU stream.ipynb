{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import zeros\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#import keras\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras import backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D,AveragePooling2D\n",
    "from keras.layers import LSTM,Bidirectional,BatchNormalization,Activation,GRU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import img_to_array,array_to_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from hilbert import hilbertCurve\n",
    "from PIL import Image,ImageChops, ImageEnhance\n",
    "import patch_hilbert_data_set as dt\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "session = tf.Session(config=config)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/xzhang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(64, kernel_size=3, strides=1, padding = 'same', \n",
    "    activation= 'relu'), input_shape=(16,64,64,3),name='block1_conv1'))# 卷积层\n",
    "model.add(TimeDistributed(Conv2D(64, kernel_size=3, strides=1, padding = 'same', \n",
    "    activation= 'relu'), name='block1_conv2'))# 卷积层\n",
    "model.add(TimeDistributed(BatchNormalization(momentum=0.1)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),name='block1_pool')))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Conv2D(128, kernel_size=3, strides=1, padding = 'same', \n",
    "    activation= 'relu'), name='block2_conv1'))\n",
    "model.add(TimeDistributed(Conv2D(128, kernel_size=3, strides=1, padding = 'same', \n",
    "    activation= 'relu'), name='block2_conv2'))\n",
    "model.add(TimeDistributed(BatchNormalization(momentum=0.1)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),name='block2_pool')))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Conv2D(256, kernel_size=3, strides=1, padding = 'same', \n",
    "    activation= 'relu'), name='block3_conv1'))\n",
    "model.add(TimeDistributed(Conv2D(256, kernel_size=3, strides=1, padding = 'same', \n",
    "    activation= 'relu'), name='block3_conv2'))\n",
    "#model.add(TimeDistributed(Conv2D(256, kernel_size=3, strides=1, padding = 'same', \n",
    "#    activation= 'relu'), name='block3_conv3'))\n",
    "model.add(TimeDistributed(BatchNormalization(momentum=0.1)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2),name='block3_pool')))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(Dropout(0.5))#wu\n",
    "model.add(GRU(256,return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(GRU(256))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256,kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(256,kernel_regularizer=regularizers.l2(0.1)))#\n",
    "model.add(BatchNormalization(momentum=0.1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))#softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (TimeDistribute (None, 16, 64, 64, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (TimeDistribute (None, 16, 64, 64, 64)    36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 16, 64, 64, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 16, 32, 32, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (TimeDistribute (None, 16, 32, 32, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (TimeDistribute (None, 16, 32, 32, 128)   147584    \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 16, 32, 32, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 16, 16, 16, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (TimeDistribute (None, 16, 16, 16, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (TimeDistribute (None, 16, 16, 16, 256)   590080    \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 16, 16, 16, 256)   1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 16, 8, 8, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 16, 16384)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16384)         0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 16, 256)           12780288  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 256)               393984    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 14,455,361\n",
      "Trainable params: 14,453,441\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01, decay=0.000015, momentum=0.9, nesterov=True)\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "lr_metric = get_lr_metric(sgd)\n",
    "def scheduler(epoch):\n",
    "    # 每隔100个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 30 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.8)\n",
    "        print(\"lr changed to {}\".format(lr * 0.8))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "metric=['acc', lr_metric]\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(#用于数据增强\n",
    "#    rotation_range=15,\n",
    "    shear_range=0.1,\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "validate_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "def data_generator(generator,images,labels,batch_size):#自定义generator，输出多标签\n",
    "    #input_generator=generator.flow(images,batch_size=batch_size)\n",
    "    num_samples=len(images)\n",
    "    input_generator=generator.flow(images,labels,batch_size=batch_size)#届时传入之前的数据增强generator\n",
    "    while True:\n",
    "        for offset in range(0,num_samples,batch_size):\n",
    "        \t#使用了flow(),每一次返回的是批量的 图片数据，组合标签[labels1,labels2]\n",
    "            batch_samples,batch_labels=input_generator.next()\n",
    "            X_train=[]\n",
    "            Y_train=[]\n",
    "            for i in range(len(batch_samples)):\n",
    "                img=batch_samples[i]\n",
    "                img = dt.read_image1(img)\n",
    "                X_train.append(img) \n",
    "                Y_train.append(batch_labels[i])\n",
    "                #print(Y_train)\n",
    "            X_train=np.array(X_train)\n",
    "            Y_train=np.array(Y_train)\n",
    "            yield X_train,Y_train#返回batch的图片数据和对应的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 160, 160, 3)\n",
      "(6000, 160, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "fileList = os.listdir('/home/Data/FF/RAW1/originalt')  # 训练数据文件夹\n",
    "data=[]\n",
    "labels=[]\n",
    "for fileName in fileList:\n",
    "    image=cv2.imread(os.path.join('/home/Data/FF/RAW1/originalt',fileName))\n",
    "    if image is not None:\n",
    "        image2=img_to_array(image)\n",
    "        data.append(image2)\n",
    "        labels.append('0')\n",
    "\n",
    "fileList = os.listdir('/home/Data/FF/RAW1/train/fake/DF')  # 训练数据文件夹  \n",
    "for fileName in fileList:\n",
    "    image=cv2.imread(os.path.join('/home/Data/FF/RAW1/train/fake/DF',fileName))\n",
    "    if image is not None:\n",
    "        image2=img_to_array(image)\n",
    "        data.append(image2)\n",
    "        labels.append('1')\n",
    "\n",
    "data=np.array(data,dtype=\"float32\")\n",
    "labels=np.array(labels,dtype=\"float32\")\n",
    "\n",
    "fileList = os.listdir('/home/Data/FF/RAW1/original')  # 训练数据文件夹\n",
    "datat=[]\n",
    "labelts=[]\n",
    "    \n",
    "for fileName in fileList:\n",
    "    image=cv2.imread(os.path.join('/home/Data/FF/RAW1/original',fileName))\n",
    "    if image is not None:\n",
    "        image2=img_to_array(image)\n",
    "        datat.append(image2)\n",
    "        labelts.append('0')\n",
    "fileList = os.listdir('/home/Data/FF/RAW1/val/fake/DF')  # 训练数据文件夹  \n",
    "for fileName in fileList:\n",
    "    image=cv2.imread(os.path.join('/home/Data/FF/RAW1/val/fake/DF',fileName))\n",
    "    if image is not None:\n",
    "        image2=img_to_array(image)\n",
    "        datat.append(image2)\n",
    "        labelts.append('1')\n",
    "\n",
    "datat=np.array(datat,dtype=\"float32\")\n",
    "labelts=np.array(labelts,dtype=\"float32\")\n",
    "\n",
    "print(data.shape)\n",
    "print(datat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "index = [i for i in range(len(data))]\n",
    "random.shuffle(index);\n",
    "data=data[index]\n",
    "labels=labels[index]\n",
    "\n",
    "indext = [i for i in range(len(datat))]\n",
    "random.shuffle(indext);\n",
    "datat=datat[indext]\n",
    "labelts=labelts[indext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train_datagen = ImageDataGenerator(#用于数据增强\n",
    "#    rotation_range=15,\n",
    "    shear_range=0.1,\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "validate_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "def data_generator(generator,images,labels,batch_size):#自定义generator，输出多标签\n",
    "    #input_generator=generator.flow(images,batch_size=batch_size)\n",
    "    num_samples=len(images)\n",
    "    input_generator=generator.flow(images,labels,batch_size=batch_size)#届时传入之前的数据增强generator\n",
    "    while True:\n",
    "        for offset in range(0,num_samples,batch_size):\n",
    "        \t#使用了flow(),每一次返回的是批量的 图片数据，组合标签[labels1,labels2]\n",
    "            batch_samples,batch_labels=input_generator.next()\n",
    "            X_train=[]\n",
    "            Y_train=[]\n",
    "            for i in range(len(batch_samples)):\n",
    "                img=batch_samples[i]\n",
    "                img = dt.read_image1(img)\n",
    "                X_train.append(img) \n",
    "                Y_train.append(batch_labels[i])\n",
    "                #print(Y_train)\n",
    "            X_train=np.array(X_train)\n",
    "            Y_train=np.array(Y_train)\n",
    "            yield X_train,Y_train#返回batch的图片数据和对应的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_validate=len(labelts)\n",
    "total_train=data.shape[0]\n",
    "filepath='./model/weights.best.FF.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,save_best_only=True,mode='max') \n",
    "callbacks_list = [checkpoint,reduce_lr]\n",
    "history=model.fit_generator(\n",
    "    data_generator(train_datagen,data,labels,batch_size),\n",
    "    epochs=50,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=data_generator(validate_datagen,datat,labelts,batch_size),\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
