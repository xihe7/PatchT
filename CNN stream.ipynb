{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import logging\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from resnet import resnet50_cbam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class Patch_CNN(nn.Module):\n",
    "    def __init__(self, model, feature_size, classes_num):\n",
    "        super(Patch_CNN, self).__init__()\n",
    "\n",
    "        self.features = model\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=56, stride=56)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=28, stride=28)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=14, stride=14)\n",
    "        self.num_ftrs = 2048 * 1 * 1\n",
    "        self.elu = nn.ELU(inplace=True)\n",
    "\n",
    "        self.classifier_concat = nn.Sequential(\n",
    "            nn.BatchNorm1d(1024 * 3),\n",
    "            nn.Linear(1024 * 3, feature_size),\n",
    "            nn.BatchNorm1d(feature_size),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(feature_size, classes_num),\n",
    "        )\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            BasicConv(self.num_ftrs//4, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n",
    "           # nn.Dropout(0.5,inplace=False),\n",
    "            BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n",
    "        )\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.num_ftrs//2),\n",
    "            nn.Linear(self.num_ftrs//2, feature_size),\n",
    "            nn.BatchNorm1d(feature_size),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(feature_size, classes_num),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        xf1, xf2, xf3, xf4, xf5 = self.features(x)\n",
    "        print(xf3.size())\n",
    "        xl1 = self.conv_block1(xf3)\n",
    "        print(xl1.size())\n",
    "        xl1 = self.max1(xl1)\n",
    "        print(xl1.size())\n",
    "        xl1 = xl1.view(xl1.size(0), -1)\n",
    "        print(xl1.size())\n",
    "        xc1 = self.classifier1(xl1)\n",
    "        print(xc1.size())\n",
    "      #  xc1 = torch.nn.Sigmoid(xc1)\n",
    "        return xc1\n",
    "    \n",
    "    \n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n",
    "                              stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5,\n",
    "                                 momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, feature_size, classes_num):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, padding=2),\n",
    "            nn.BatchNorm2d(32, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, 1, padding=1),\n",
    "            nn.BatchNorm2d(64, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, 1, padding=1),\n",
    "            nn.BatchNorm2d(128, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, 1, padding=1),\n",
    "            nn.BatchNorm2d(256, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 512, 3, 1, padding=1),\n",
    "            nn.BatchNorm2d(512, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 2, 1),\n",
    "            nn.BatchNorm2d(512, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "\n",
    "        )\n",
    "\n",
    "        self.max1 = nn.MaxPool2d(kernel_size=13, stride=13)\n",
    "        self.max2 = nn.MaxPool2d(kernel_size=28, stride=28)\n",
    "        self.max3 = nn.MaxPool2d(kernel_size=14, stride=14)\n",
    "        self.num_ftrs = 2048 * 1 * 1\n",
    "        self.elu = nn.ELU(inplace=True)\n",
    "\n",
    "        self.classifier_concat = nn.Sequential(\n",
    "            nn.BatchNorm1d(1024 * 3),\n",
    "            nn.Linear(1024 * 3, feature_size),\n",
    "            nn.BatchNorm1d(feature_size),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(feature_size, classes_num),\n",
    "        )\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            BasicConv(self.num_ftrs//4, feature_size, kernel_size=1, stride=1, padding=0, relu=True),\n",
    "            \n",
    "            BasicConv(feature_size, self.num_ftrs//2, kernel_size=3, stride=1, padding=1, relu=True)\n",
    "        )\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.num_ftrs//2),\n",
    "            nn.Linear(self.num_ftrs//2, feature_size),\n",
    "            nn.BatchNorm1d(feature_size),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(feature_size, classes_num),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        xf3 = self.features(x)\n",
    "    \n",
    "\n",
    "        xl1 = self.conv_block1(xf3)\n",
    " \n",
    "        #xl1 = self.max1(xl1)\n",
    "        xl1 = xl1.view(xl1.size(0), -1)\n",
    "        xc1 = self.classifier1(xl1)\n",
    "        xc1 = torch.Sigmoid(xc1)\n",
    "        return xc1\n",
    "    \n",
    "    \n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.out_channels = out_planes\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n",
    "                              stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5,\n",
    "                                 momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from Resnet import *\n",
    "\n",
    "def cosine_anneal_schedule(t, nb_epoch, lr):\n",
    "    cos_inner = np.pi * (t % (nb_epoch))  # t - 1 is used when t has 1-based indexing.\n",
    "    cos_inner /= (nb_epoch)\n",
    "    cos_out = np.cos(cos_inner) + 1\n",
    "\n",
    "    return float(lr / 2 * cos_out)\n",
    "\n",
    "\n",
    "def load_model(model_name, pretrain=True, require_grad=True):\n",
    "    print('==> Building model..')\n",
    "    if model_name == 'resnet50_Patch_CNN':\n",
    "        net = resnet50(pretrained=pretrain)\n",
    "        for param in net.parameters():\n",
    "            param.requires_grad = require_grad\n",
    "        net = Patch_CNN(net, 512, 2)\n",
    "    if model_name == 'CNN':\n",
    "        net = CNN(512, 2)\n",
    "    if model_name == 'resnet50_cbam':\n",
    "        net = resnet50_cbam(pretrained=pretrain)\n",
    "        for param in net.parameters():\n",
    "            param.requires_grad = require_grad\n",
    "        net = Patch_CNN(net, 512, 2)\n",
    "    return net\n",
    "\n",
    "\n",
    "def model_info(model): \n",
    "    n_p = sum(x.numel() for x in model.parameters())  \n",
    "    n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  \n",
    "    print('\\n%5s %50s %9s %12s %20s %12s %12s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))\n",
    "    for i, (name, p) in enumerate(model.named_parameters()):\n",
    "        name = name.replace('module_list.', '')\n",
    "        print('%5g %50s %9s %12g %20s %12.3g %12.3g' % (\n",
    "            i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))\n",
    "    print('Model Summary: %g layers, %g parameters, %g gradients\\n' % (i + 1, n_p, n_g))\n",
    "\n",
    "\n",
    "def patch_transformation(images, n):\n",
    "    l = []\n",
    "    for a in range(n):\n",
    "        for b in range(n):\n",
    "            l.append([a, b])\n",
    "    block_size = 448 // n\n",
    "    rounds = n ** 2\n",
    "    random.shuffle(l)\n",
    "    patchrandom = images.clone()\n",
    "    for i in range(rounds):\n",
    "        x, y = l[i]\n",
    "        temp = patchrandom[..., 0:block_size, 0:block_size].clone()\n",
    "        patchrandom[..., 0:block_size, 0:block_size] = patchrandom[..., x * block_size:(x + 1) * block_size,\n",
    "                                                y * block_size:(y + 1) * block_size].clone()\n",
    "        patchrandom[..., x * block_size:(x + 1) * block_size, y * block_size:(y + 1) * block_size] = temp\n",
    "\n",
    "    return patchrandom\n",
    "\n",
    "\n",
    "def test(net, criterion, batch_size):\n",
    "    net.eval()\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    correct_com = 0\n",
    "    total = 0\n",
    "    idx = 0\n",
    "    device = torch.device(\"cuda:3\")\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Scale((500, 500)),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    testset = torchvision.datasets.ImageFolder(root='/home/Data/FF/C40/DFt/val',\n",
    "                                               transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        idx = batch_idx\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        output_1= net(inputs)\n",
    "\n",
    "        loss = criterion(output_1, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(output_1.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Step: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)' % (\n",
    "            batch_idx, test_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total, ))\n",
    "\n",
    "    test_acc = 100. * float(correct) / total\n",
    "    test_acc_en = 100. * float(correct_com) / total\n",
    "    test_loss = test_loss / (idx + 1)\n",
    "\n",
    "    return test_acc, test_acc_en, test_loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nb_epoch, batch_size, store_name, resume=False, start_epoch=0, model_path=None):\n",
    "    # setup output\n",
    "    exp_dir = store_name\n",
    "    try:\n",
    "        os.stat(exp_dir)\n",
    "    except:\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    print(use_cuda)\n",
    "\n",
    "    # Data\n",
    "    print('==> Preparing..')\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Scale((500, 500)),\n",
    "        transforms.RandomCrop(448, padding=8),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.ImageFolder(root='/home/Data/FF/C40/DFt/train', transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    # Model\n",
    "    if resume:\n",
    "        net = torch.load(model_path)\n",
    "    else:\n",
    "        net = load_model(model_name='resnet50_Patch_CNN', pretrain=True, require_grad=True)\n",
    "    netp = torch.nn.DataParallel(net, device_ids=[3])\n",
    "\n",
    "    # GPU\n",
    "    device = torch.device(\"cuda:3\")\n",
    "    net.to(device)\n",
    "    # cudnn.benchmark = True\n",
    "\n",
    "    CELoss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD([\n",
    "        {'params': net.classifier_concat.parameters(), 'lr': 0.0005},\n",
    "        {'params': net.conv_block1.parameters(), 'lr': 0.0005},\n",
    "        {'params': net.classifier1.parameters(), 'lr': 0.0005},#0.002\n",
    "        {'params': net.features.parameters(), 'lr': 0.00005}#0.0002\n",
    "\n",
    "    ],\n",
    "        momentum=0.9, weight_decay=5e-4)\n",
    "    \n",
    "\n",
    "    max_val_acc = 0\n",
    "    lr = [0.0005, 0.0005, 0.0005, 0.00005]\n",
    "\n",
    "    for epoch in range(start_epoch, nb_epoch):\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        train_loss1 = 0\n",
    "        train_loss2 = 0\n",
    "        train_loss3 = 0\n",
    "        train_loss4 = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        idx = 0\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            idx = batch_idx\n",
    "            if inputs.shape[0] < batch_size:\n",
    "                continue\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "\n",
    "            # update learning rate\n",
    "            for nlr in range(len(optimizer.param_groups)):\n",
    "                optimizer.param_groups[nlr]['lr'] = cosine_anneal_schedule(epoch, nb_epoch, lr[nlr])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            inputs1 = patch_transformation(inputs, 4)\n",
    "            output_1 = netp(inputs1)\n",
    "            #print(output_1)\n",
    "            #print(targets)\n",
    "            loss1 = CELoss(output_1, targets) * 1\n",
    "            loss1.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            _, predicted = torch.max(output_1.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "            train_loss +=  loss1.item()\n",
    "\n",
    "            if batch_idx % 50 == 0:\n",
    "                print(\n",
    "                    'Step: %d | Loss1: %.3f | Acc: %.3f%% (%d/%d)' % (\n",
    "                    batch_idx, train_loss / (batch_idx + 1), \n",
    "                    100. * float(correct) / total, correct, total))\n",
    "\n",
    "        train_acc = 100. * float(correct) / total\n",
    "        train_loss = train_loss / (idx + 1)\n",
    "        with open(exp_dir + '/results_train.txt', 'a') as file:\n",
    "            file.write(\n",
    "                'Iteration %d | train_acc = %.5f | train_loss = %.5f |\\n' % (\n",
    "                epoch, train_acc, train_loss))\n",
    "\n",
    "        if epoch < 40:\n",
    "            val_acc, val_acc_com, val_loss = test(net, CELoss, 3)\n",
    "            if val_acc_com > max_val_acc:\n",
    "                max_val_acc = val_acc_com\n",
    "                net.cpu()\n",
    "                torch.save(net, './' + store_name + '/bestmodel.pth')\n",
    "                net.to(device)\n",
    "            net.cpu()\n",
    "            torch.save(net, './' + store_name + '/'+str(epoch)+'model.pth')\n",
    "            net.to(device)\n",
    "            with open(exp_dir + '/results_test.txt', 'a') as file:\n",
    "                file.write('Iteration %d, test_acc = %.5f, test_acc_combined = %.5f, test_loss = %.6f\\n' % (\n",
    "                epoch, val_acc, val_acc_com, val_loss))\n",
    "        else:\n",
    "            net.cpu()\n",
    "            torch.save(net, './' + store_name + '/'+str(epoch)+'model.pth')\n",
    "            net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(nb_epoch=20,             # number of epoch\n",
    "         batch_size=16,         # batch size\n",
    "         store_name='',     # folder for output\n",
    "         resume=False,          # resume training from checkpoint\n",
    "         start_epoch=0,         # the start epoch number when you resume the training\n",
    "         model_path='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.Scale((550, 550)),\n",
    "        transforms.CenterCrop(448),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "testset=[]\n",
    "testset = torchvision.datasets.ImageFolder(root='/home/data/newtrain/val',\n",
    "                                               transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "PATH = \"./style.pth\" #7\n",
    "net = torch.load(PATH)\n",
    "\n",
    "net.to(torch.device(\"cuda:3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "correct_com = 0\n",
    "total = 0\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        idx = batch_idx\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, targets = inputs.to(torch.device(\"cuda:3\")), targets.to(torch.device(\"cuda:3\"))\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        #print(targets)\n",
    "        output_1= net(inputs)\n",
    "        #print(output_1)\n",
    "\n",
    "        loss = criterion(output_1, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(output_1.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Step: %d | Loss: %.3f | Acc: %.3f%% (%d/%d)' % (\n",
    "            batch_idx, test_loss / (batch_idx + 1), 100. * float(correct) / total, correct, total, ))\n",
    "\n",
    "    test_acc = 100. * float(correct) / total\n",
    "    test_acc_en = 100. * float(correct_com) / total\n",
    "    test_loss = test_loss / (idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.92"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc#93.1625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
